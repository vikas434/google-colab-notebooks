{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf472f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal Car Bumper Recommendation System\n",
    "\n",
    "# Import necessary libraries\n",
    "from vertexai.generative_models import GenerativeModel, Image\n",
    "import IPython\n",
    "import typing\n",
    "import urllib.request\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "# Initialize the Vertex AI SDK for your project\n",
    "# Replace '[your-project-id]' with your actual Google Cloud project ID\n",
    "PROJECT_ID = '[your-project-id]'\n",
    "LOCATION = 'us-central1'  # You can choose the location nearest to you\n",
    "\n",
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# Load the Gemini 1.0 Pro Vision model\n",
    "multimodal_model = GenerativeModel('gemini-1.0-pro-vision')\n",
    "\n",
    "# Helper functions for image handling\n",
    "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        if response.headers['Content-Type'] not in ('image/png', 'image/jpeg'):\n",
    "            raise Exception('Image can only be in PNG or JPEG format')\n",
    "        return response.read()\n",
    "\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "def display_image(image: Image, max_width: int = 600, max_height: int = 350) -> None:\n",
    "    pil_image = typing.cast(PIL_Image.Image, image._pil_image).convert('RGB')\n",
    "    image_width, image_height = pil_image.size\n",
    "    if max_width < image_width or max_height < image_height:\n",
    "        pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "    ipython_image = IPython.display.Image(data=pil_image.tobytes(), format=pil_image.format)\n",
    "    IPython.display.display(ipython_image)\n",
    "\n",
    "# Replace 'your_car_image_url_here' with the URL of your car image\n",
    "car_image_url = 'your_car_image_url_here'\n",
    "\n",
    "# Replace these URLs with the actual URLs of your backside bumper options\n",
    "bumper_image_urls = [\n",
    "    'bumper_option_1_url_here',\n",
    "    'bumper_option_2_url_here',\n",
    "    'bumper_option_3_url_here',\n",
    "    'bumper_option_4_url_here',\n",
    "]\n",
    "\n",
    "# Load images\n",
    "car_image = load_image_from_url(car_image_url)\n",
    "bumper_images = [load_image_from_url(url) for url in bumper_image_urls]\n",
    "\n",
    "# Create content for the multimodal prompt\n",
    "contents = [\n",
    "    'Given the following car:',\n",
    "    car_image,\n",
    "    'And these backside bumper options:',\n",
    "    'Option 1:',\n",
    "    bumper_images[0],\n",
    "    'Option 2:',\n",
    "    bumper_images[1],\n",
    "    'Option 3:',\n",
    "    bumper_images[2],\n",
    "    'Option 4:',\n",
    "    bumper_images[3],\n",
    "    'Recommend the most suitable backside bumper for the car, considering style, color, and overall aesthetics:',\n",
    "]\n",
    "\n",
    "# Generate recommendation\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "# Display prompt and response\n",
    "print('-------Prompt--------')\n",
    "for content in contents:\n",
    "    if isinstance(content, Image):\n",
    "        display_image(content)\n",
    "    else:\n",
    "        print(content)\n",
    "\n",
    "print('\\n-------Response--------')\n",
    "for response in responses:\n",
    "    print(response.text, end='')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
